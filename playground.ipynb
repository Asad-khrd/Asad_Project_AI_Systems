{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c37c6ec1-bf2d-4787-a8df-d9ba4bd314bb",
   "metadata": {},
   "source": [
    "# Assignment 1: Data Collection & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e30101d-0b21-4fd6-a4dd-b63caf9a5cbc",
   "metadata": {},
   "source": [
    "## 1. Setup: Import Libraries and Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b6f07b8-e866-418d-ab99-9b371bfbbf3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025c1407-6c4b-421c-97c4-c4613595ab2d",
   "metadata": {},
   "source": [
    "## 2. Define directories for stock prices and tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005bf53b-4df5-4e84-b8d3-62f0c2601f90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directory paths for stock prices and tweets\n",
    "stock_directory = 'data/price/raw'\n",
    "tweet_directory = 'data/tweet/raw'\n",
    "\n",
    "stock_data = {}  # Dictionary to store stock data\n",
    "tweets_data = {}  # Dictionary to store tweet data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e1cedb-064d-4acc-b99b-d8766a218e94",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55bda08-3892-47a8-bc42-15c6d06f787e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_files = [file for file in os.listdir(stock_directory) if file.endswith('.csv')]\n",
    "\n",
    "for file in csv_files:\n",
    "    symbol = file.split('.')[0]  # Extract stock symbol from filename\n",
    "    df = pd.read_csv(os.path.join(stock_directory, file))\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.fillna(method='ffill', inplace=True)  # Forward fill missing values\n",
    "    stock_data[symbol] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f36a1d-a46d-43b2-8a09-8bfadea7c895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>340.996857</td>\n",
       "      <td>341.221008</td>\n",
       "      <td>335.492493</td>\n",
       "      <td>339.248413</td>\n",
       "      <td>339.248413</td>\n",
       "      <td>3793200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-09-05</td>\n",
       "      <td>338.730347</td>\n",
       "      <td>341.968231</td>\n",
       "      <td>338.301971</td>\n",
       "      <td>339.089020</td>\n",
       "      <td>339.089020</td>\n",
       "      <td>3429100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-09-06</td>\n",
       "      <td>341.699219</td>\n",
       "      <td>348.638214</td>\n",
       "      <td>341.086517</td>\n",
       "      <td>348.394135</td>\n",
       "      <td>348.394135</td>\n",
       "      <td>6109700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>348.693024</td>\n",
       "      <td>354.795135</td>\n",
       "      <td>347.532349</td>\n",
       "      <td>351.756531</td>\n",
       "      <td>351.756531</td>\n",
       "      <td>6490100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>353.554779</td>\n",
       "      <td>355.074097</td>\n",
       "      <td>347.891022</td>\n",
       "      <td>349.076569</td>\n",
       "      <td>349.076569</td>\n",
       "      <td>5139100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Open        High         Low       Close   Adj Close  \\\n",
       "0 2012-09-04  340.996857  341.221008  335.492493  339.248413  339.248413   \n",
       "1 2012-09-05  338.730347  341.968231  338.301971  339.089020  339.089020   \n",
       "2 2012-09-06  341.699219  348.638214  341.086517  348.394135  348.394135   \n",
       "3 2012-09-07  348.693024  354.795135  347.532349  351.756531  351.756531   \n",
       "4 2012-09-10  353.554779  355.074097  347.891022  349.076569  349.076569   \n",
       "\n",
       "    Volume  \n",
       "0  3793200  \n",
       "1  3429100  \n",
       "2  6109700  \n",
       "3  6490100  \n",
       "4  5139100  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data['GOOG'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41e2ed0-57fc-4ce1-9c88-0fdb4a07ff2b",
   "metadata": {},
   "source": [
    "## 4. Load and Preprocess Tweets Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6706943d-359b-4597-bf42-a9713454ba67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweet_threshold = 635  # Minimum tweets required for a company\n",
    "\n",
    "for stock_folder in os.listdir(tweet_directory):\n",
    "    stock_path = os.path.join(tweet_directory, stock_folder)\n",
    "    \n",
    "    if os.path.isdir(stock_path):\n",
    "        all_tweets = []\n",
    "        count = 0  # Count of tweet files for each stock\n",
    "\n",
    "        for tweet_file in os.listdir(stock_path):\n",
    "            file_path = os.path.join(stock_path, tweet_file)\n",
    "\n",
    "            if os.path.isfile(file_path):\n",
    "                count += 1\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    for line in f:\n",
    "                        try:\n",
    "                            tweet_json = json.loads(line.strip())\n",
    "                            tweet_data = {\n",
    "                                'Date': pd.to_datetime(tweet_json['created_at']),\n",
    "                                'Text': tweet_json['text'],\n",
    "                                'User': tweet_json['user']['screen_name'],\n",
    "                                'Followers': tweet_json['user']['followers_count'],\n",
    "                                'Friends': tweet_json['user']['friends_count']\n",
    "                            }\n",
    "                            all_tweets.append(tweet_data)\n",
    "                        except json.JSONDecodeError:\n",
    "                            print(f\"Error decoding JSON in file {file_path}\")\n",
    "\n",
    "        if count >= tweet_threshold:  # Store data only if threshold met\n",
    "            tweets_data[stock_folder] = pd.DataFrame(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ee26a06-c6b2-4949-8134-e72d0905a240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, ['FB', 'GOOG', 'D', 'BAC', 'AMZN', 'INTC', 'T', 'MSFT', 'AAPL', 'C'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_data), list(tweets_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0886bcb-1786-4804-a81e-798ee5c3a68e",
   "metadata": {},
   "source": [
    "## 5. Align Dates in Stock and Tweet Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e970294c-0891-4e17-9940-1eaf3a59015a",
   "metadata": {},
   "source": [
    "* Grouping tweets by date and restructure them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9072fa0-6917-4370-9653-263cc3234a97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for stock, df in tweets_data.items():\n",
    "    df['Date'] = pd.to_datetime(df['Date']).dt.date  # Convert to date only\n",
    "    grouped = df.groupby('Date').agg({\n",
    "        'Text': list,\n",
    "        'User': list,\n",
    "        'Followers': list,\n",
    "        'Friends': list\n",
    "    }).reset_index()\n",
    "    tweets_data[stock] = grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c301979-d813-41b1-96af-307415a5d546",
   "metadata": {},
   "source": [
    "* Filtering stock data to match tweet data companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "646ad3ca-1212-4a27-a835-15c631a269be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of companies with both stock and tweet data: 10\n"
     ]
    }
   ],
   "source": [
    "stock_data = {symbol: df for symbol, df in stock_data.items() if symbol in tweets_data}\n",
    "print(f\"Number of companies with both stock and tweet data: {len(stock_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e7383b-a40e-43fb-aa2d-0cfb17ef626c",
   "metadata": {},
   "source": [
    "## Merge Stock and Tweet Data for a Company"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8916f7e-9f8e-49f4-977e-941cf37cdb61",
   "metadata": {},
   "source": [
    "* Below is the example of merging stock and tweet data for one company (GOOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4de67978-4048-4b27-b9db-dfdf6b17e3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Text</th>\n",
       "      <th>User</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Friends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>18.080000</td>\n",
       "      <td>18.270000</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>17.730000</td>\n",
       "      <td>17.730000</td>\n",
       "      <td>46622400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-09-05</td>\n",
       "      <td>18.270000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>18.580000</td>\n",
       "      <td>18.580000</td>\n",
       "      <td>60781800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-09-06</td>\n",
       "      <td>18.740000</td>\n",
       "      <td>19.260000</td>\n",
       "      <td>18.719999</td>\n",
       "      <td>18.959999</td>\n",
       "      <td>18.959999</td>\n",
       "      <td>46066500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>19.420000</td>\n",
       "      <td>18.780001</td>\n",
       "      <td>18.980000</td>\n",
       "      <td>18.980000</td>\n",
       "      <td>36371700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>19.059999</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>18.549999</td>\n",
       "      <td>18.809999</td>\n",
       "      <td>18.809999</td>\n",
       "      <td>24797800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       Open       High        Low      Close  Adj Close    Volume  \\\n",
       "0 2012-09-04  18.080000  18.270000  17.549999  17.730000  17.730000  46622400   \n",
       "1 2012-09-05  18.270000  18.750000  18.180000  18.580000  18.580000  60781800   \n",
       "2 2012-09-06  18.740000  19.260000  18.719999  18.959999  18.959999  46066500   \n",
       "3 2012-09-07  19.100000  19.420000  18.780001  18.980000  18.980000  36371700   \n",
       "4 2012-09-10  19.059999  19.200001  18.549999  18.809999  18.809999  24797800   \n",
       "\n",
       "  Text User Followers Friends  \n",
       "0  NaN  NaN       NaN     NaN  \n",
       "1  NaN  NaN       NaN     NaN  \n",
       "2  NaN  NaN       NaN     NaN  \n",
       "3  NaN  NaN       NaN     NaN  \n",
       "4  NaN  NaN       NaN     NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data['FB']['Date'] = pd.to_datetime(stock_data['FB']['Date'])\n",
    "tweets_data['FB']['Date'] = pd.to_datetime(tweets_data['FB']['Date'])\n",
    "\n",
    "merged_data = stock_data['FB'].merge(tweets_data['FB'], on='Date', how='left')\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7170132a-dbcc-44de-af99-c3e5f6c5d3d5",
   "metadata": {},
   "source": [
    "## Apply the Same Merging Process for All Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de6f3f27-aa8f-401b-a1ff-5f1f990e3530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for stock in stock_data.keys():\n",
    "    if stock in tweets_data:\n",
    "        stock_data[stock]['Date'] = pd.to_datetime(stock_data[stock]['Date'])\n",
    "        tweets_data[stock]['Date'] = pd.to_datetime(tweets_data[stock]['Date'])\n",
    "\n",
    "        stock_data[stock] = stock_data[stock].merge(tweets_data[stock], on='Date', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0018fb15-4aa3-460b-b052-24857cf7a600",
   "metadata": {},
   "source": [
    "* Displaying filtered merged data for GOOG (if it has tweet data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aea2c22-2408-4693-a1e3-49a80d204284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Text</th>\n",
       "      <th>User</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Friends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>398.799988</td>\n",
       "      <td>399.359985</td>\n",
       "      <td>394.019989</td>\n",
       "      <td>397.970001</td>\n",
       "      <td>397.970001</td>\n",
       "      <td>2137800</td>\n",
       "      <td>[RT @MadKindlePromos: Several incredible novel...</td>\n",
       "      <td>[JohnRosePutnam, waheedfaizi]</td>\n",
       "      <td>[881, 89]</td>\n",
       "      <td>[860, 210]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>398.290009</td>\n",
       "      <td>402.709991</td>\n",
       "      <td>396.220001</td>\n",
       "      <td>396.440002</td>\n",
       "      <td>396.440002</td>\n",
       "      <td>2210200</td>\n",
       "      <td>[The first employees at Google, Amazon and Sub...</td>\n",
       "      <td>[AlvaroConnell, CNBCJosh]</td>\n",
       "      <td>[1, 2668]</td>\n",
       "      <td>[0, 279]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>395.850006</td>\n",
       "      <td>397.000000</td>\n",
       "      <td>388.420013</td>\n",
       "      <td>393.630005</td>\n",
       "      <td>393.630005</td>\n",
       "      <td>3170600</td>\n",
       "      <td>[RT @SteveTappin: 9 Bar Charts: Apple vs. Amaz...</td>\n",
       "      <td>[WorldOfCEOs, GavinGreenberg, InvestEdInc]</td>\n",
       "      <td>[250614, 66, 261]</td>\n",
       "      <td>[39119, 0, 328]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>2014-01-07</td>\n",
       "      <td>395.040009</td>\n",
       "      <td>398.470001</td>\n",
       "      <td>394.290009</td>\n",
       "      <td>398.029999</td>\n",
       "      <td>398.029999</td>\n",
       "      <td>1916000</td>\n",
       "      <td>[If $AMZN starts accepting #bitcoin, #bitcoin ...</td>\n",
       "      <td>[insidemarkets, mjwmonty, QP_Service, QP_Service]</td>\n",
       "      <td>[68, 50, 23, 24]</td>\n",
       "      <td>[135, 90, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>398.470001</td>\n",
       "      <td>403.000000</td>\n",
       "      <td>396.040009</td>\n",
       "      <td>401.920013</td>\n",
       "      <td>401.920013</td>\n",
       "      <td>2316500</td>\n",
       "      <td>[RT @WSJ: A look inside Amazon's rigorous hiri...</td>\n",
       "      <td>[FAnjum1, GavinGreenberg, fin_vestor, fuz1on, ...</td>\n",
       "      <td>[83, 70, 249, 402, 485, 58, 140, 9]</td>\n",
       "      <td>[118, 0, 0, 2001, 169, 536, 222, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        Open        High         Low       Close   Adj Close  \\\n",
       "333 2014-01-02  398.799988  399.359985  394.019989  397.970001  397.970001   \n",
       "334 2014-01-03  398.290009  402.709991  396.220001  396.440002  396.440002   \n",
       "335 2014-01-06  395.850006  397.000000  388.420013  393.630005  393.630005   \n",
       "336 2014-01-07  395.040009  398.470001  394.290009  398.029999  398.029999   \n",
       "337 2014-01-08  398.470001  403.000000  396.040009  401.920013  401.920013   \n",
       "\n",
       "      Volume                                               Text  \\\n",
       "333  2137800  [RT @MadKindlePromos: Several incredible novel...   \n",
       "334  2210200  [The first employees at Google, Amazon and Sub...   \n",
       "335  3170600  [RT @SteveTappin: 9 Bar Charts: Apple vs. Amaz...   \n",
       "336  1916000  [If $AMZN starts accepting #bitcoin, #bitcoin ...   \n",
       "337  2316500  [RT @WSJ: A look inside Amazon's rigorous hiri...   \n",
       "\n",
       "                                                  User  \\\n",
       "333                      [JohnRosePutnam, waheedfaizi]   \n",
       "334                          [AlvaroConnell, CNBCJosh]   \n",
       "335         [WorldOfCEOs, GavinGreenberg, InvestEdInc]   \n",
       "336  [insidemarkets, mjwmonty, QP_Service, QP_Service]   \n",
       "337  [FAnjum1, GavinGreenberg, fin_vestor, fuz1on, ...   \n",
       "\n",
       "                               Followers                              Friends  \n",
       "333                            [881, 89]                           [860, 210]  \n",
       "334                            [1, 2668]                             [0, 279]  \n",
       "335                    [250614, 66, 261]                      [39119, 0, 328]  \n",
       "336                     [68, 50, 23, 24]                      [135, 90, 1, 1]  \n",
       "337  [83, 70, 249, 402, 485, 58, 140, 9]  [118, 0, 0, 2001, 169, 536, 222, 0]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = stock_data['AMZN'][stock_data['AMZN']['Text'].notna()]\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48347050-c90f-472c-a111-1f2ac7144aca",
   "metadata": {},
   "source": [
    "## Displaying Basic Info of filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35b5158-bf52-41af-8e64-cfbad418b752",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 529 entries, 333 to 897\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Date       529 non-null    datetime64[ns]\n",
      " 1   Open       529 non-null    float64       \n",
      " 2   High       529 non-null    float64       \n",
      " 3   Low        529 non-null    float64       \n",
      " 4   Close      529 non-null    float64       \n",
      " 5   Adj Close  529 non-null    float64       \n",
      " 6   Volume     529 non-null    int64         \n",
      " 7   Text       529 non-null    object        \n",
      " 8   User       529 non-null    object        \n",
      " 9   Followers  529 non-null    object        \n",
      " 10  Friends    529 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(5), int64(1), object(4)\n",
      "memory usage: 49.6+ KB\n"
     ]
    }
   ],
   "source": [
    "filtered_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0a3713d-e9a5-4146-bbd8-162bbde39916",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>529</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>5.290000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2015-02-15 22:43:46.843100160</td>\n",
       "      <td>424.825047</td>\n",
       "      <td>429.493422</td>\n",
       "      <td>419.349490</td>\n",
       "      <td>424.561891</td>\n",
       "      <td>424.561891</td>\n",
       "      <td>4.157928e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2014-01-02 00:00:00</td>\n",
       "      <td>284.399994</td>\n",
       "      <td>290.420013</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>286.950012</td>\n",
       "      <td>286.950012</td>\n",
       "      <td>1.091200e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2014-07-18 00:00:00</td>\n",
       "      <td>327.799988</td>\n",
       "      <td>331.720001</td>\n",
       "      <td>323.269989</td>\n",
       "      <td>327.239990</td>\n",
       "      <td>327.239990</td>\n",
       "      <td>2.679500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2015-02-24 00:00:00</td>\n",
       "      <td>378.410004</td>\n",
       "      <td>383.000000</td>\n",
       "      <td>375.839996</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>3.600100e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2015-09-10 00:00:00</td>\n",
       "      <td>527.650024</td>\n",
       "      <td>532.599976</td>\n",
       "      <td>519.219971</td>\n",
       "      <td>526.030029</td>\n",
       "      <td>526.030029</td>\n",
       "      <td>4.674500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2016-03-31 00:00:00</td>\n",
       "      <td>691.890015</td>\n",
       "      <td>696.440002</td>\n",
       "      <td>686.380005</td>\n",
       "      <td>693.969971</td>\n",
       "      <td>693.969971</td>\n",
       "      <td>2.385610e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>114.944392</td>\n",
       "      <td>116.202614</td>\n",
       "      <td>113.041267</td>\n",
       "      <td>114.735843</td>\n",
       "      <td>114.735843</td>\n",
       "      <td>2.575615e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Date        Open        High         Low  \\\n",
       "count                            529  529.000000  529.000000  529.000000   \n",
       "mean   2015-02-15 22:43:46.843100160  424.825047  429.493422  419.349490   \n",
       "min              2014-01-02 00:00:00  284.399994  290.420013  284.000000   \n",
       "25%              2014-07-18 00:00:00  327.799988  331.720001  323.269989   \n",
       "50%              2015-02-24 00:00:00  378.410004  383.000000  375.839996   \n",
       "75%              2015-09-10 00:00:00  527.650024  532.599976  519.219971   \n",
       "max              2016-03-31 00:00:00  691.890015  696.440002  686.380005   \n",
       "std                              NaN  114.944392  116.202614  113.041267   \n",
       "\n",
       "            Close   Adj Close        Volume  \n",
       "count  529.000000  529.000000  5.290000e+02  \n",
       "mean   424.561891  424.561891  4.157928e+06  \n",
       "min    286.950012  286.950012  1.091200e+06  \n",
       "25%    327.239990  327.239990  2.679500e+06  \n",
       "50%    379.000000  379.000000  3.600100e+06  \n",
       "75%    526.030029  526.030029  4.674500e+06  \n",
       "max    693.969971  693.969971  2.385610e+07  \n",
       "std    114.735843  114.735843  2.575615e+06  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb0a483c-fdf2-466a-af00-0dfa03df2201",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         0\n",
       "Open         0\n",
       "High         0\n",
       "Low          0\n",
       "Close        0\n",
       "Adj Close    0\n",
       "Volume       0\n",
       "Text         0\n",
       "User         0\n",
       "Followers    0\n",
       "Friends      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8dac21-a195-4d4b-ac84-ba2a6d43613c",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69e24cc8-7a55-428d-8fb6-6f0f9aa5d724",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total companies with merged stock and tweet data: 10\n",
      "Companies: ['GOOG', 'BAC', 'AMZN', 'MSFT', 'T', 'D', 'FB', 'AAPL', 'C', 'INTC']\n"
     ]
    }
   ],
   "source": [
    "print(\"Total companies with merged stock and tweet data:\", len(stock_data))\n",
    "print(\"Companies:\", list(stock_data.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b62794-f098-4427-b70c-337a034d637f",
   "metadata": {},
   "source": [
    "# Assignment 2: Further Data Preprocessing and Initial Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2effe08b-030f-4813-8863-e219d77a76ae",
   "metadata": {},
   "source": [
    "* We will implement LSTM, and as of now, we will ignore tweets and some other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "415bab27-4ce0-4bff-bdc1-2664d04cd81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Preprocessing\n",
    "# Drop unnecessary columns\n",
    "data = filtered_data.drop(['Text', 'User', 'Followers', 'Friends'], axis=1)\n",
    "\n",
    "# Sort by date and set 'Date' as index (optional)\n",
    "data = data.sort_values('Date').set_index('Date')\n",
    "\n",
    "# Feature scaling using MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4be949bd-1bd0-4a57-acfd-05cf3549dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Prepare the data for LSTM\n",
    "def create_sequences(data, time_step=60):\n",
    "    X, y = [], []\n",
    "    for i in range(time_step, len(data)):\n",
    "        X.append(data[i-time_step:i, :])  # 60 timesteps of input\n",
    "        y.append(data[i, 3])  # Target: 'Close' column at index 3\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create sequences with a window size of 60\n",
    "time_step = 60\n",
    "X, y = create_sequences(scaled_data, time_step)\n",
    "\n",
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f345d874-3b75-4471-8525-f955a7bc3c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the LSTM Model\n",
    "class StockLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(StockLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h_0, c_0))\n",
    "        out = self.fc(out[:, -1, :])  # Get output from the last time step\n",
    "        return out\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "input_size = X_train.shape[2]  # Number of features (7 in our case)\n",
    "hidden_size = 50\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "model = StockLSTM(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27cc1bcf-0e7c-4eb2-9754-f08bb33116fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.0336\n",
      "Epoch [20/100], Loss: 0.0196\n",
      "Epoch [30/100], Loss: 0.0038\n",
      "Epoch [40/100], Loss: 0.0036\n",
      "Epoch [50/100], Loss: 0.0018\n",
      "Epoch [60/100], Loss: 0.0018\n",
      "Epoch [70/100], Loss: 0.0015\n",
      "Epoch [80/100], Loss: 0.0014\n",
      "Epoch [90/100], Loss: 0.0014\n",
      "Epoch [100/100], Loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8404aa35-7347-410e-9d04-76ba84f2cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test).cpu().numpy()\n",
    "\n",
    "# Create a placeholder array with the same number of columns as the original data (7)\n",
    "# Populate only the 'Close' column (index 3) with predictions\n",
    "predictions_padded = np.zeros((predictions.shape[0], scaled_data.shape[1]))\n",
    "predictions_padded[:, 3] = predictions.flatten()  # Index 3 is 'Close'\n",
    "\n",
    "y_test_padded = np.zeros((y_test.shape[0], scaled_data.shape[1]))\n",
    "y_test_padded[:, 3] = y_test.numpy().flatten()\n",
    "\n",
    "# Inverse transform to get back to the original scale\n",
    "predictions_rescaled = scaler.inverse_transform(predictions_padded)[:, 3]\n",
    "y_test_rescaled = scaler.inverse_transform(y_test_padded)[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d5699fe-1676-44ed-999e-65352b77e682",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 21.1455\n",
      "Mean Squared Error (MSE): 715.7555\n",
      "Root Mean Squared Error (RMSE): 26.7536\n",
      "R² Score: 0.7725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Step 6: Calculate accuracy metrics\n",
    "mae = mean_absolute_error(y_test_rescaled, predictions_rescaled)\n",
    "mse = mean_squared_error(y_test_rescaled, predictions_rescaled)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_rescaled, predictions_rescaled)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f85f07-5128-415c-af71-02f2c5f9178b",
   "metadata": {},
   "source": [
    "* As we have ten companies data we will work on, but as of now, we had implemented model on only one company data (AMZN)\n",
    "* Also, as of now we have just used stock data for analysis, we havn't used tweet sentiments, we'll also make use of tweet sentiments in our model later on\n",
    "* Also, we have just implemented the model, the hyperparameter tuning and other validation and testing steps we'll do later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-llm",
   "language": "python",
   "name": "hf-llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
